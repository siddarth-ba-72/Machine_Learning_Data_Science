{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Layer DNN (Pima Diabetes Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = np.loadtxt('./pima-indians-diabetes.data', delimiter=',')\n",
    "\n",
    "##Attribute Information:\n",
    "#1. Number of times pregnant\n",
    "#2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "#3. Diastolic blood pressure (mm Hg)\n",
    "#4. Triceps skin fold thickness (mm)\n",
    "#5. 2-Hour serum insulin (mu U/ml)\n",
    "#6. Body mass index (weight in kg/(height in m)^2)\n",
    "#7. Diabetes pedigree function\n",
    "#8. Age (years)\n",
    "#9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima[np.where(pima[:,0]>8),0] = 8 #Pregnancy-more than 8 should be taken as 8\n",
    "pima[np.where(pima[:,7]<=30),7] = 1 #quantize the age in 5 buckets\n",
    "pima[np.where((pima[:,7]>30) & (pima[:,7]<=40)),7] = 2\n",
    "pima[np.where((pima[:,7]>40) & (pima[:,7]<=50)),7] = 3\n",
    "pima[np.where((pima[:,7]>50) & (pima[:,7]<=60)),7] = 4\n",
    "pima[np.where(pima[:,7]>60),7] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X = pima[:, [1, 5]]  #we will use two variables only for simplicity.\n",
    "y = pima[:,8:9]\n",
    "print('Class labels:', np.unique(y))\n",
    "\n",
    "\n",
    "# Splitting data into 70% training and 30% test data:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,\n",
    "                                                    random_state=1, stratify=y)\n",
    "y_train = np.array(y_train.ravel())\n",
    "y_test = np.array(y_test.ravel())\n",
    "\n",
    "## Standardizing the features:\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /Users/ranju/Documents/RANMURAL/CellStrat Lab/venv/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/ranju/Documents/RANMURAL/CellStrat Lab/venv/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.8306682, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 89 vs previous value: 89. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 613.648\n",
      "INFO:tensorflow:loss = 0.80810845, step = 100 (0.166 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 120 vs previous value: 120. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 1186.22\n",
      "INFO:tensorflow:loss = 0.7965822, step = 200 (0.082 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 204 vs previous value: 204. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 1334.12\n",
      "INFO:tensorflow:loss = 0.78801864, step = 300 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1408.59\n",
      "INFO:tensorflow:loss = 0.78100103, step = 400 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1497.63\n",
      "INFO:tensorflow:loss = 0.7749778, step = 500 (0.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 1424.97\n",
      "INFO:tensorflow:loss = 0.76968265, step = 600 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1143.95\n",
      "INFO:tensorflow:loss = 0.76493424, step = 700 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 871.627\n",
      "INFO:tensorflow:loss = 0.76060367, step = 801 (0.115 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 812 vs previous value: 812. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 852 vs previous value: 852. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 494.303\n",
      "INFO:tensorflow:loss = 0.7566208, step = 900 (0.202 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/model/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Loss for final step: 0.7530082.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f81c72a26a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns =[tf.feature_column.numeric_column(\"x\",shape=[np.shape(X)[1]])]\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                        #hidden_units=[5, 10, 5], n_classes=2, model_dir=\"./model\")\n",
    "                                        hidden_units=[5], n_classes=2, model_dir=\"/tmp/model\")\n",
    "\n",
    "def train_input_fn():\n",
    "    return {\"x\":np.array(X_train_std)},np.array(y_train,dtype=np.int)\n",
    "\n",
    "classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-10T13:50:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Inference Time : 0.43145s\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-10-13:50:18\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.45454547, accuracy_baseline = 0.64935064, auc = 0.2465432, auc_precision_recall = 0.23666263, average_loss = 0.76290977, global_step = 1000, label/mean = 0.35064936, loss = 0.76290977, precision = 0.13114753, prediction/mean = 0.48858795, recall = 0.09876543\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/model/model.ckpt-1000\n",
      "Test Accuracy: 0.454545\n"
     ]
    }
   ],
   "source": [
    "def test_input_fn():\n",
    "    return {\"x\":np.array(X_test_std)},np.array(y_test,dtype=np.int)\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn,steps=1)[\"accuracy\"]\n",
    "print(\"Test Accuracy: {0:f}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.2):\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array([xx1.ravel(), xx2.ravel()]).T},\n",
    "                                                          num_epochs=1,shuffle=False)\n",
    "        \n",
    "    print('start predict')\n",
    "    predictions= list(classifier.predict(input_fn=predict_input_fn))\n",
    "    print('end predict')\n",
    "    \n",
    "    Z= [p[\"classes\"] for p in predictions]  \n",
    "    Z=np.array(Z)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    \n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot all samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8,\n",
    "                    c=colors[idx], marker=markers[idx], label=cl, edgecolor='black')\n",
    "\n",
    "    if test_idx:   # # highlight test samples.\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "        plt.scatter(X_test[:, 0], X_test[:, 1], c='', edgecolor='black', alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o', s=100, label='test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_estimator.python.estimator.api._v2.estimator' has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-24413bfc23e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Glucose'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BMI'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fa81d2c0913e>\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[0;34m(X, y, classifier, test_idx, resolution)\u001b[0m\n\u001b[1;32m     11\u001b[0m                            np.arange(x2_min, x2_max, resolution))\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": np.array([xx1.ravel(), xx2.ravel()]).T},\n\u001b[0m\u001b[1;32m     14\u001b[0m                                                           num_epochs=1,shuffle=False)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_estimator.python.estimator.api._v2.estimator' has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "plot_decision_regions(X_test_std, y_test, classifier=classifier)\n",
    "\n",
    "plt.xlabel('Glucose')\n",
    "plt.ylabel('BMI')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Diabetes classifier using Neural Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
